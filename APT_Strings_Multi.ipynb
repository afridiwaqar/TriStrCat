{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56b7192b-4e9d-4b06-8f68-c22780aa8e96",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-20 12:12:48.797673: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-09-20 12:12:48.827950: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-09-20 12:12:48.828392: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-20 12:12:49.362543: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, roc_curve, auc\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "\n",
    "# Importing TensorFlow/Keras for Neural Network\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1fbb5536-ed5f-414a-a9c4-d3708a425ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('Final_Datasets_just_string_Balance.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ba1885b-d452-4f3c-a340-4d5078d5d299",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature extraction: N-Grams and Entropy\n",
    "def calculate_entropy(s):\n",
    "    p, lns = Counter(s), float(len(s))\n",
    "    return -sum(count/lns * math.log(count/lns, 2) for count in p.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bea3641a-8ebb-4cdc-bbbf-6a2dd8a81036",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_n_grams(text, n=3):\n",
    "    n_grams = [text[i:i+n] for i in range(len(text)-n+1)]\n",
    "    return ' '.join(n_grams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78b184a5-db4b-40d6-a80f-54fc2bde70d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['N_GRAMS'] = df['STRING'].apply(lambda x: generate_n_grams(str(x), 3))\n",
    "df['ENTROPY'] = df['STRING'].apply(lambda x: calculate_entropy(str(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "215ff486-ef5a-49a0-8d4b-3aa1980ba7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features (N-grams and entropy) and target\n",
    "X_ngrams = df['N_GRAMS']\n",
    "X_entropy = df['ENTROPY'].values.reshape(-1, 1)\n",
    "y = df['TARGET']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da38ce17-ad54-4271-841c-ba8ca5bf238f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert N-grams to vectorized format using TF-IDF\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X_ngrams_tfidf = vectorizer.fit_transform(X_ngrams).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7bf584de-6aad-4f42-ba5b-945194cc3b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate N-grams and entropy as features\n",
    "X = np.hstack((X_ngrams_tfidf, X_entropy))\n",
    "\n",
    "# Encode target labels\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be4a5bca-97a7-406d-bbbe-7ea056967b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute class weights\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(y), y=y)\n",
    "class_weights_dict = dict(enumerate(class_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "854eca98-99fb-4c6a-a541-106009e7a6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define models\n",
    "models_dict = {\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000),\n",
    "    'Random Forest': RandomForestClassifier(),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(),\n",
    "    'k-NN': KNeighborsClassifier(),\n",
    "    'Gaussian Naive Bayes': GaussianNB(),\n",
    "    'Neural Network': None,  # Placeholder for Neural Network that we'll define below\n",
    "    'SVC (Linear Kernel)': SVC(kernel='linear', probability=True),\n",
    "    'SVC (RBF Kernel)': SVC(kernel='rbf', probability=True),\n",
    "    'SVC (Poly Kernel)': SVC(kernel='poly', probability=True),\n",
    "    'SVC (Sigmoid Kernel)': SVC(kernel='sigmoid', probability=True),\n",
    "    'AdaBoost': AdaBoostClassifier(),\n",
    "    'Linear Discriminant Analysis': LinearDiscriminantAnalysis(),\n",
    "    'Quadratic Discriminant Analysis': QuadraticDiscriminantAnalysis(),\n",
    "    'Multinomial Naive Bayes': MultinomialNB(),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e9a96165-1219-4aa2-a524-bd6165c5fca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Stratified K-Fold cross-validation\n",
    "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "96ab9e29-d7fb-4950-973e-88a22f825833",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_neural_network(input_dim):\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(128, activation='relu', input_dim=input_dim))\n",
    "    model.add(layers.Dropout(0.3))\n",
    "    model.add(layers.Dense(64, activation='relu'))\n",
    "    model.add(layers.Dense(3, activation='softmax'))\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7e09dfb6-0bdc-490e-a767-c78fb1211fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the None placeholder with the actual neural network model\n",
    "models_dict['Neural Network'] = create_neural_network(X.shape[1])\n",
    "\n",
    "# Lists to store results\n",
    "results = {}\n",
    "roc_figures = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3f479f88-a9c0-42ca-9182-9353a35fc31c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 0s 792us/step\n",
      "19/19 [==============================] - 0s 680us/step\n",
      "19/19 [==============================] - 0s 718us/step\n",
      "19/19 [==============================] - 0s 693us/step\n",
      "19/19 [==============================] - 0s 794us/step\n",
      "19/19 [==============================] - 0s 741us/step\n",
      "19/19 [==============================] - 0s 708us/step\n",
      "19/19 [==============================] - 0s 706us/step\n",
      "19/19 [==============================] - 0s 699us/step\n",
      "19/19 [==============================] - 0s 711us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/waqar/.local/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/home/waqar/.local/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/home/waqar/.local/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/home/waqar/.local/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/home/waqar/.local/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/home/waqar/.local/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/home/waqar/.local/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/home/waqar/.local/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/home/waqar/.local/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/home/waqar/.local/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    }
   ],
   "source": [
    "# Loop through models\n",
    "for model_name, model in models_dict.items():\n",
    "    accuracy_scores, precision_scores, recall_scores, f1_scores, roc_auc_scores = [], [], [], [], []\n",
    "    tprs, aucs = [], []\n",
    "    mean_fpr = np.linspace(0, 1, 100)\n",
    "    \n",
    "    for train_index, test_index in skf.split(X, y_encoded):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y_encoded[train_index], y_encoded[test_index]\n",
    "        \n",
    "        # Train model\n",
    "        if model_name == 'Neural Network':  # Custom NN model\n",
    "            model = create_neural_network(X_train.shape[1])  # Re-initialize NN model for each fold\n",
    "            history = model.fit(X_train, pd.get_dummies(y_train), epochs=10, batch_size=32, validation_data=(X_test, pd.get_dummies(y_test)), class_weight=class_weights_dict, verbose=0)\n",
    "            y_pred_prob = model.predict(X_test)\n",
    "            y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "        else:\n",
    "            model.fit(X_train, y_train)\n",
    "            y_pred_prob = model.predict_proba(X_test)\n",
    "            y_pred = model.predict(X_test)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        accuracy_scores.append(accuracy_score(y_test, y_pred))\n",
    "        precision_scores.append(precision_score(y_test, y_pred, average='weighted'))\n",
    "        recall_scores.append(recall_score(y_test, y_pred, average='weighted'))\n",
    "        f1_scores.append(f1_score(y_test, y_pred, average='weighted'))\n",
    "        roc_auc_scores.append(roc_auc_score(pd.get_dummies(y_test), y_pred_prob, multi_class='ovr'))  # Correct ROC AUC for multi-class\n",
    "        \n",
    "        # Compute ROC curve and AUC\n",
    "        fpr, tpr, _ = roc_curve(pd.get_dummies(y_test).to_numpy().ravel(), y_pred_prob.ravel())\n",
    "        tprs.append(np.interp(mean_fpr, fpr, tpr))\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        aucs.append(roc_auc)\n",
    "    \n",
    "    # Calculate mean and standard deviation for scores\n",
    "    results[model_name] = {\n",
    "        'accuracy': (np.mean(accuracy_scores), np.std(accuracy_scores)),\n",
    "        'precision': (np.mean(precision_scores), np.std(precision_scores)),\n",
    "        'recall': (np.mean(recall_scores), np.std(recall_scores)),\n",
    "        'f1': (np.mean(f1_scores), np.std(f1_scores)),\n",
    "        'roc_auc': (np.mean(roc_auc_scores), np.std(roc_auc_scores)),\n",
    "    }\n",
    "\n",
    "    # Generate ROC curves\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r', alpha=.8)\n",
    "    mean_tpr = np.mean(tprs, axis=0)\n",
    "    mean_tpr[-1] = 1.0\n",
    "    mean_auc = auc(mean_fpr, mean_tpr)\n",
    "    plt.plot(mean_fpr, mean_tpr, color='b', label=f'{model_name} (AUC = {mean_auc:.2f})', lw=2, alpha=.8)\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC Curve')\n",
    "    plt.legend(loc='lower right')\n",
    "    roc_figures[model_name] = plt.gcf()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8d3f17d7-f766-438c-924f-bf1973714f93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression - Accuracy: 0.8925 ± 0.0175\n",
      "Logistic Regression - Precision: 0.8930 ± 0.0173\n",
      "Logistic Regression - Recall: 0.8925 ± 0.0175\n",
      "Logistic Regression - F1-Score: 0.8920 ± 0.0179\n",
      "Logistic Regression - ROC AUC: 0.9763 ± 0.0065\n",
      "\n",
      "\n",
      "Random Forest - Accuracy: 0.9332 ± 0.0123\n",
      "Random Forest - Precision: 0.9332 ± 0.0124\n",
      "Random Forest - Recall: 0.9332 ± 0.0123\n",
      "Random Forest - F1-Score: 0.9330 ± 0.0124\n",
      "Random Forest - ROC AUC: 0.9899 ± 0.0031\n",
      "\n",
      "\n",
      "Gradient Boosting - Accuracy: 0.9298 ± 0.0117\n",
      "Gradient Boosting - Precision: 0.9298 ± 0.0117\n",
      "Gradient Boosting - Recall: 0.9298 ± 0.0117\n",
      "Gradient Boosting - F1-Score: 0.9295 ± 0.0119\n",
      "Gradient Boosting - ROC AUC: 0.9870 ± 0.0050\n",
      "\n",
      "\n",
      "k-NN - Accuracy: 0.8937 ± 0.0123\n",
      "k-NN - Precision: 0.8954 ± 0.0119\n",
      "k-NN - Recall: 0.8937 ± 0.0123\n",
      "k-NN - F1-Score: 0.8940 ± 0.0123\n",
      "k-NN - ROC AUC: 0.9676 ± 0.0078\n",
      "\n",
      "\n",
      "Gaussian Naive Bayes - Accuracy: 0.8426 ± 0.0143\n",
      "Gaussian Naive Bayes - Precision: 0.8423 ± 0.0144\n",
      "Gaussian Naive Bayes - Recall: 0.8426 ± 0.0143\n",
      "Gaussian Naive Bayes - F1-Score: 0.8412 ± 0.0145\n",
      "Gaussian Naive Bayes - ROC AUC: 0.9029 ± 0.0101\n",
      "\n",
      "\n",
      "Neural Network - Accuracy: 0.9275 ± 0.0103\n",
      "Neural Network - Precision: 0.9288 ± 0.0098\n",
      "Neural Network - Recall: 0.9275 ± 0.0103\n",
      "Neural Network - F1-Score: 0.9276 ± 0.0102\n",
      "Neural Network - ROC AUC: 0.9882 ± 0.0026\n",
      "\n",
      "\n",
      "SVC (Linear Kernel) - Accuracy: 0.9051 ± 0.0155\n",
      "SVC (Linear Kernel) - Precision: 0.9056 ± 0.0155\n",
      "SVC (Linear Kernel) - Recall: 0.9051 ± 0.0155\n",
      "SVC (Linear Kernel) - F1-Score: 0.9048 ± 0.0158\n",
      "SVC (Linear Kernel) - ROC AUC: 0.9782 ± 0.0060\n",
      "\n",
      "\n",
      "SVC (RBF Kernel) - Accuracy: 0.8362 ± 0.0149\n",
      "SVC (RBF Kernel) - Precision: 0.8378 ± 0.0156\n",
      "SVC (RBF Kernel) - Recall: 0.8362 ± 0.0149\n",
      "SVC (RBF Kernel) - F1-Score: 0.8328 ± 0.0153\n",
      "SVC (RBF Kernel) - ROC AUC: 0.9522 ± 0.0081\n",
      "\n",
      "\n",
      "SVC (Poly Kernel) - Accuracy: 0.8523 ± 0.0158\n",
      "SVC (Poly Kernel) - Precision: 0.8551 ± 0.0160\n",
      "SVC (Poly Kernel) - Recall: 0.8523 ± 0.0158\n",
      "SVC (Poly Kernel) - F1-Score: 0.8496 ± 0.0163\n",
      "SVC (Poly Kernel) - ROC AUC: 0.9555 ± 0.0082\n",
      "\n",
      "\n",
      "SVC (Sigmoid Kernel) - Accuracy: 0.4867 ± 0.0262\n",
      "SVC (Sigmoid Kernel) - Precision: 0.5641 ± 0.0234\n",
      "SVC (Sigmoid Kernel) - Recall: 0.4867 ± 0.0262\n",
      "SVC (Sigmoid Kernel) - F1-Score: 0.4875 ± 0.0255\n",
      "SVC (Sigmoid Kernel) - ROC AUC: 0.6476 ± 0.0135\n",
      "\n",
      "\n",
      "AdaBoost - Accuracy: 0.8030 ± 0.0174\n",
      "AdaBoost - Precision: 0.8019 ± 0.0165\n",
      "AdaBoost - Recall: 0.8030 ± 0.0174\n",
      "AdaBoost - F1-Score: 0.7993 ± 0.0196\n",
      "AdaBoost - ROC AUC: 0.8948 ± 0.0095\n",
      "\n",
      "\n",
      "Linear Discriminant Analysis - Accuracy: 0.6653 ± 0.0228\n",
      "Linear Discriminant Analysis - Precision: 0.6741 ± 0.0245\n",
      "Linear Discriminant Analysis - Recall: 0.6653 ± 0.0228\n",
      "Linear Discriminant Analysis - F1-Score: 0.6659 ± 0.0231\n",
      "Linear Discriminant Analysis - ROC AUC: 0.7507 ± 0.0163\n",
      "\n",
      "\n",
      "Quadratic Discriminant Analysis - Accuracy: 0.8617 ± 0.0233\n",
      "Quadratic Discriminant Analysis - Precision: 0.8869 ± 0.0139\n",
      "Quadratic Discriminant Analysis - Recall: 0.8617 ± 0.0233\n",
      "Quadratic Discriminant Analysis - F1-Score: 0.8630 ± 0.0225\n",
      "Quadratic Discriminant Analysis - ROC AUC: 0.8958 ± 0.0173\n",
      "\n",
      "\n",
      "Multinomial Naive Bayes - Accuracy: 0.8149 ± 0.0186\n",
      "Multinomial Naive Bayes - Precision: 0.8133 ± 0.0197\n",
      "Multinomial Naive Bayes - Recall: 0.8149 ± 0.0186\n",
      "Multinomial Naive Bayes - F1-Score: 0.8105 ± 0.0193\n",
      "Multinomial Naive Bayes - ROC AUC: 0.9244 ± 0.0089\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display results like in the table format you provided\n",
    "for model_name, scores in results.items():\n",
    "    print(f\"{model_name} - Accuracy: {scores['accuracy'][0]:.4f} ± {scores['accuracy'][1]:.4f}\")\n",
    "    print(f\"{model_name} - Precision: {scores['precision'][0]:.4f} ± {scores['precision'][1]:.4f}\")\n",
    "    print(f\"{model_name} - Recall: {scores['recall'][0]:.4f} ± {scores['recall'][1]:.4f}\")\n",
    "    print(f\"{model_name} - F1-Score: {scores['f1'][0]:.4f} ± {scores['f1'][1]:.4f}\")\n",
    "    print(f\"{model_name} - ROC AUC: {scores['roc_auc'][0]:.4f} ± {scores['roc_auc'][1]:.4f}\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0b74043f-4864-4b45-b4f1-6669ee601d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To save the ROC figures\n",
    "for model_name, fig in roc_figures.items():\n",
    "    fig.savefig(f'ROC_{model_name}.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
